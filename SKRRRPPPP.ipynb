{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrfZ5IyG6PkcShZkIuU5n4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yayanhidayaat/klasifikasi/blob/main/SKRRRPPPP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# üîπ Path dataset di Google Drive dan lokal\n",
        "GDRIVE_DATASET_PATH = \"/content/drive/Shareddrives/STORE ASYFA/Yayan/riceleafs\"\n",
        "LOCAL_DATASET_PATH = \"/content/riceleafs\"\n",
        "ZIP_FILE_PATH = \"/content/riceleafs.zip\"\n",
        "RUNTIME_FILE = \"/content/drive/Shareddrives/STORE ASYFA/Yayan/runtime.pkl\"\n",
        "KAGGLE_JSON_PATH = \"/content/drive/Shareddrives/STORE ASYFA/Yayan/kaggle.json\"\n",
        "\n",
        "def check_and_copy_dataset():\n",
        "    if os.path.exists(GDRIVE_DATASET_PATH) and len(os.listdir(GDRIVE_DATASET_PATH)) > 0:\n",
        "        print(\"‚úÖ Dataset ditemukan di Google Drive! Menyalin ke lokal...\")\n",
        "        if os.path.exists(LOCAL_DATASET_PATH):\n",
        "            shutil.rmtree(LOCAL_DATASET_PATH)\n",
        "        shutil.copytree(GDRIVE_DATASET_PATH, LOCAL_DATASET_PATH)\n",
        "    else:\n",
        "        download_dataset_from_kaggle()\n",
        "\n",
        "def download_dataset_from_kaggle():\n",
        "    print(\"‚ö†Ô∏è Dataset belum ada di Google Drive. Mengunduh dari Kaggle...\")\n",
        "    !pip install -q kaggle\n",
        "    kaggle_config_dir = \"/root/.kaggle\"\n",
        "    os.makedirs(kaggle_config_dir, exist_ok=True)\n",
        "    if os.path.exists(KAGGLE_JSON_PATH):\n",
        "        shutil.copy(KAGGLE_JSON_PATH, os.path.join(kaggle_config_dir, \"kaggle.json\"))\n",
        "        os.chmod(os.path.join(kaggle_config_dir, \"kaggle.json\"), 0o600)\n",
        "    else:\n",
        "        raise FileNotFoundError(\"‚ùå kaggle.json tidak ditemukan di Google Drive!\")\n",
        "    if not os.path.exists(ZIP_FILE_PATH):\n",
        "        print(\"üîΩ Mengunduh dataset dari Kaggle...\")\n",
        "        os.system(f\"kaggle datasets download -d shayanriyaz/riceleafs -p /content\")\n",
        "    extract_and_save_dataset()\n",
        "\n",
        "def extract_and_save_dataset():\n",
        "    if not os.path.exists(ZIP_FILE_PATH):\n",
        "        raise FileNotFoundError(f\"‚ùå Gagal mengunduh dataset. File {ZIP_FILE_PATH} tidak ditemukan!\")\n",
        "    print(\"üìÇ Mengekstrak dataset...\")\n",
        "    os.makedirs(LOCAL_DATASET_PATH, exist_ok=True)\n",
        "    with zipfile.ZipFile(ZIP_FILE_PATH, 'r') as zip_ref:\n",
        "        zip_ref.extractall(LOCAL_DATASET_PATH)\n",
        "    print(\"üíæ Menyimpan dataset ke Google Drive...\")\n",
        "    os.makedirs(GDRIVE_DATASET_PATH, exist_ok=True)\n",
        "    shutil.copytree(LOCAL_DATASET_PATH, GDRIVE_DATASET_PATH, dirs_exist_ok=True)\n",
        "\n",
        "def select_correct_dataset_folder():\n",
        "    folder_option1 = os.path.join(LOCAL_DATASET_PATH, \"RiceLeafs\")\n",
        "    folder_option2 = os.path.join(LOCAL_DATASET_PATH, \"riceleafs\")\n",
        "    if os.path.exists(folder_option1):\n",
        "        return folder_option1\n",
        "    elif os.path.exists(folder_option2):\n",
        "        return folder_option2\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"‚ùå Tidak ditemukan folder 'RiceLeafs' atau 'riceleafs' di dalam {LOCAL_DATASET_PATH}\")\n",
        "\n",
        "def save_runtime_data():\n",
        "    runtime_data = {\"dataset_downloaded\": True, \"download_path\": LOCAL_DATASET_PATH}\n",
        "    with open(RUNTIME_FILE, \"wb\") as f:\n",
        "        pickle.dump(runtime_data, f)\n",
        "\n",
        "check_and_copy_dataset()\n",
        "dataset_path = select_correct_dataset_folder()\n",
        "save_runtime_data()\n",
        "\n",
        "print(f\"\\n‚úÖ Dataset siap digunakan! Folder yang dipilih: {dataset_path}\")\n",
        "print(\"üìÇ Isi folder dataset:\", os.listdir(dataset_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZa64Z6SGxvG",
        "outputId": "991897bd-b729-4659-a50b-8f4553f0f0aa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Dataset ditemukan di Google Drive! Menyalin ke lokal...\n",
            "\n",
            "‚úÖ Dataset siap digunakan! Folder yang dipilih: /content/riceleafs/RiceLeafs\n",
            "üìÇ Isi folder dataset: ['train', 'validation']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0MXJdBqiE6Kb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffd8b232-a6ad-40f4-a4e6-8cd0666ca92e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Path dataset dan penyimpanan preprocessing telah disiapkan!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, save_img\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
        "from openpyxl import load_workbook\n",
        "\n",
        "# üîπ Gunakan path dataset yang sudah dipilih\n",
        "DATASET_PATH = dataset_path  # Pastikan variabel ini dari kode sebelumnya\n",
        "\n",
        "# üîπ Cek apakah dataset tersedia\n",
        "if not os.path.exists(DATASET_PATH) or not os.listdir(DATASET_PATH):\n",
        "    raise FileNotFoundError(f\"‚ùå Dataset tidak ditemukan di {DATASET_PATH}\")\n",
        "\n",
        "# üîπ Kelas dalam dataset\n",
        "CLASSES = [\"BrownSpot\", \"Healthy\", \"Hispa\", \"LeafBlast\"]\n",
        "\n",
        "# üîπ Menentukan direktori penyimpanan setelah preprocessing\n",
        "PROCESSED_DATASET_NAME = \"/content/drive/Shareddrives/STORE ASYFA/Yayan/riceleafs/Rice_Leafs_Dataset_Aug_Preprocessed_224x224\"\n",
        "SAVE_PATHS = {cls: os.path.join(PROCESSED_DATASET_NAME, cls) for cls in CLASSES}\n",
        "\n",
        "# üîπ Buat direktori penyimpanan jika belum ada\n",
        "os.makedirs(PROCESSED_DATASET_NAME, exist_ok=True)\n",
        "for cls in CLASSES:\n",
        "    os.makedirs(SAVE_PATHS[cls], exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Path dataset dan penyimpanan preprocessing telah disiapkan!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# üîπ Isi file environment_setup.py\n",
        "environment_setup_code = f\"\"\"# environment_setup.py\n",
        "\n",
        "import os\n",
        "\n",
        "# Path ke dataset\n",
        "DATASET_PATH = \"/content/drive/Shareddrives/STORE ASYFA/Yayan/riceleafs/RiceLeafs\"\n",
        "\n",
        "# Kelas dalam dataset (ubah sesuai dengan dataset Anda)\n",
        "CLASSES = [\"Healthy\", \"Hispa\", \"BrownSpot\", \"LeafBlast\"]\n",
        "\n",
        "# Path penyimpanan setelah pemrosesan\n",
        "PROCESSED_DATASET_NAME = \"/content/drive/Shareddrives/STORE ASYFA/Yayan/riceleafs/Rice_Leafs_Dataset_Aug_Preprocessed_224x224\"\n",
        "SAVE_PATHS = {{cls: os.path.join(PROCESSED_DATASET_NAME, cls) for cls in CLASSES}}\n",
        "\"\"\"\n",
        "\n",
        "# üîπ Membuat file environment_setup.py\n",
        "with open(\"environment_setup.py\", \"w\") as f:\n",
        "    f.write(environment_setup_code)\n",
        "\n",
        "print(\"‚úÖ File environment_setup.py berhasil dibuat!\")\n"
      ],
      "metadata": {
        "id": "CAwuFmx3Ug1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f297b09e-ae0a-4cd8-d7af-eae759e55196"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ File environment_setup.py berhasil dibuat!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, save_img\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# üîπ Impor konfigurasi dari environment_setup.py\n",
        "from environment_setup import DATASET_PATH, CLASSES\n",
        "\n",
        "# üîπ Tentukan path penyimpanan hasil augmentasi\n",
        "SAVE_PROCESSED_PATH = \"/content/processed_images\"\n",
        "os.makedirs(SAVE_PROCESSED_PATH, exist_ok=True)\n",
        "SAVE_PATHS = {cls: os.path.join(SAVE_PROCESSED_PATH, cls) for cls in CLASSES}\n",
        "for path in SAVE_PATHS.values():\n",
        "    os.makedirs(os.path.join(path, \"images\"), exist_ok=True)\n",
        "\n",
        "# üîπ Mengecek apakah dataset tersedia dan tidak kosong\n",
        "if not os.path.exists(DATASET_PATH) or not os.listdir(DATASET_PATH):\n",
        "    raise FileNotFoundError(f\"‚ùå Folder dataset '{DATASET_PATH}' tidak ditemukan atau kosong!\")\n",
        "\n",
        "# üîπ Mengumpulkan file gambar berdasarkan kelas\n",
        "class_filespath = {cls: [] for cls in CLASSES}\n",
        "for root, _, files in os.walk(DATASET_PATH):\n",
        "    class_name = Path(root).name\n",
        "    if class_name in class_filespath:\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):  # Hanya gambar\n",
        "                img_path = os.path.join(root, file)\n",
        "                class_filespath[class_name].append(img_path)\n",
        "\n",
        "# üîπ Hitung jumlah gambar sebelum augmentasi\n",
        "original_counts = {cls: len(files) for cls, files in class_filespath.items()}\n",
        "print(f\"üìä Jumlah gambar sebelum augmentasi: {original_counts}\")\n",
        "\n",
        "# üîπ Fungsi untuk mengubah gambar menjadi array dengan ukuran 224x224\n",
        "def images_to_array(filespath, img_size=224):\n",
        "    images_arr = []\n",
        "    for filepath in tqdm(filespath, desc=\"üì∏ Processing Images\"):\n",
        "        image = load_img(filepath, color_mode=\"rgb\", target_size=(img_size, img_size))\n",
        "        image = img_to_array(image) / 255.0  # Normalisasi (0-1)\n",
        "        images_arr.append(image)\n",
        "    return np.array(images_arr, dtype=np.float32)\n",
        "\n",
        "# üîπ Mengonversi dataset ke dalam array\n",
        "arrays_to_save = {cls: images_to_array(class_filespath[cls]) for cls in CLASSES if class_filespath[cls]}\n",
        "\n",
        "# üîπ Menyimpan gambar yang telah diproses\n",
        "for cls, images in arrays_to_save.items():\n",
        "    save_path_images = os.path.join(SAVE_PATHS[cls], \"images\")\n",
        "    os.makedirs(save_path_images, exist_ok=True)  # Pastikan direktori ada\n",
        "\n",
        "    for idx, image_arr in enumerate(tqdm(images, desc=f\"üíæ Saving {cls} images\"), 1):\n",
        "        save_img(os.path.join(save_path_images, f\"{cls}_{idx}.jpg\"), image_arr)\n",
        "\n",
        "# üîπ Augmentasi & Oversampling Data\n",
        "if arrays_to_save:\n",
        "    max_class = max(arrays_to_save, key=lambda cls: len(arrays_to_save[cls]))\n",
        "    max_count = len(arrays_to_save[max_class])  # Jumlah gambar kelas terbesar\n",
        "\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    for cls, images in arrays_to_save.items():\n",
        "        save_path_images = os.path.join(SAVE_PATHS[cls], \"images\")\n",
        "        os.makedirs(save_path_images, exist_ok=True)\n",
        "\n",
        "        image_count = len(images)\n",
        "\n",
        "        # üîπ Augmentasi hanya jika jumlah gambar kurang dari kelas terbesar\n",
        "        if image_count < max_count:\n",
        "            oversample_count = max_count - image_count\n",
        "            print(f\"üîÑ Augmenting '{cls}' ({image_count} ‚ûù {max_count})\")\n",
        "\n",
        "            aug_images = []\n",
        "            aug_generator = datagen.flow(images, batch_size=1)\n",
        "            for _ in tqdm(range(oversample_count), desc=f\"üîÑ Generating augmented {cls} images\"):\n",
        "                batch = next(aug_generator)\n",
        "                aug_images.append(batch[0])\n",
        "\n",
        "            # Simpan hasil augmentasi\n",
        "            for idx, image_arr in enumerate(aug_images, 1):\n",
        "                save_img(os.path.join(save_path_images, f\"{cls}_aug_{idx}.jpg\"), image_arr)\n",
        "\n",
        "            print(f\"‚úÖ {cls} selesai diaugmentasi ({image_count + len(aug_images)})\")\n",
        "\n",
        "# üîπ Validasi jumlah gambar setelah augmentasi\n",
        "final_counts = {cls: len(os.listdir(os.path.join(SAVE_PATHS[cls], \"images\"))) for cls in CLASSES}\n",
        "print(f\"\\nüìä Jumlah gambar setelah augmentasi: {final_counts}\")\n"
      ],
      "metadata": {
        "id": "Tb0neQGuFily",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a98f4f48-94a5-48e1-db5a-d863e2204f04"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Jumlah gambar sebelum augmentasi: {'Healthy': 1488, 'Hispa': 565, 'BrownSpot': 523, 'LeafBlast': 779}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üì∏ Processing Images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1488/1488 [04:48<00:00,  5.15it/s]\n",
            "üì∏ Processing Images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 565/565 [04:14<00:00,  2.22it/s]\n",
            "üì∏ Processing Images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 523/523 [03:43<00:00,  2.34it/s]\n",
            "üì∏ Processing Images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 779/779 [05:14<00:00,  2.47it/s]\n",
            "üíæ Saving Healthy images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1488/1488 [00:02<00:00, 510.96it/s]\n",
            "üíæ Saving Hispa images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 565/565 [00:01<00:00, 534.58it/s]\n",
            "üíæ Saving BrownSpot images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 523/523 [00:01<00:00, 513.63it/s]\n",
            "üíæ Saving LeafBlast images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 779/779 [00:01<00:00, 558.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Augmenting 'Hispa' (565 ‚ûù 1488)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üîÑ Generating augmented Hispa images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 923/923 [00:25<00:00, 36.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Hispa selesai diaugmentasi (1488)\n",
            "üîÑ Augmenting 'BrownSpot' (523 ‚ûù 1488)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üîÑ Generating augmented BrownSpot images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 965/965 [00:19<00:00, 48.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ BrownSpot selesai diaugmentasi (1488)\n",
            "üîÑ Augmenting 'LeafBlast' (779 ‚ûù 1488)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üîÑ Generating augmented LeafBlast images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 709/709 [00:15<00:00, 45.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ LeafBlast selesai diaugmentasi (1488)\n",
            "\n",
            "üìä Jumlah gambar setelah augmentasi: {'Healthy': 1488, 'Hispa': 1488, 'BrownSpot': 1488, 'LeafBlast': 1488}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from environment_setup import CLASSES, SAVE_PATHS\n",
        "\n",
        "# üîπ Hitung jumlah gambar setelah augmentasi\n",
        "augmented_counts = {cls: len(os.listdir(os.path.join(SAVE_PATHS[cls], \"images\"))) for cls in CLASSES}\n",
        "\n",
        "# üîπ Menampilkan grafik sebelum & sesudah augmentasi\n",
        "def plot_data_distribution(original_counts, augmented_counts):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    # üîπ Grafik sebelum augmentasi\n",
        "    axes[0].bar(original_counts.keys(), original_counts.values(), color='skyblue')\n",
        "    axes[0].set_title(\"Jumlah Gambar Sebelum Augmentasi\")\n",
        "    axes[0].set_xlabel(\"Kelas\")\n",
        "    axes[0].set_ylabel(\"Jumlah Gambar\")\n",
        "    axes[0].set_xticklabels(CLASSES, rotation=30)\n",
        "\n",
        "    # üîπ Grafik setelah augmentasi\n",
        "    axes[1].bar(augmented_counts.keys(), augmented_counts.values(), color='lightcoral')\n",
        "    axes[1].set_title(\"Jumlah Gambar Setelah Augmentasi\")\n",
        "    axes[1].set_xlabel(\"Kelas\")\n",
        "    axes[1].set_ylabel(\"Jumlah Gambar\")\n",
        "    axes[1].set_xticklabels(CLASSES, rotation=30)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# üîπ Panggil fungsi plotting\n",
        "plot_data_distribution(original_counts, augmented_counts)\n"
      ],
      "metadata": {
        "id": "d-lCXxxvaNjh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "outputId": "03c665ac-c784-42cd-d4bd-38223b4c3302"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-47ca1be39eb8>:17: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  axes[0].set_xticklabels(CLASSES, rotation=30)\n",
            "<ipython-input-7-47ca1be39eb8>:24: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  axes[1].set_xticklabels(CLASSES, rotation=30)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  import os\n",
        "  import pandas as pd\n",
        "  from sklearn.preprocessing import OneHotEncoder\n",
        "  from sklearn.utils import shuffle\n",
        "  from tqdm import tqdm\n",
        "  from environment_setup import DATASET_PATH, CLASSES  # Impor variabel lingkungan\n",
        "\n",
        "  # üîπ Path ke folder Train & Validation\n",
        "  TRAIN_PATH = os.path.join(DATASET_PATH, \"train\")\n",
        "  VAL_PATH = os.path.join(DATASET_PATH, \"validation\")\n",
        "\n",
        "  # üîπ Periksa apakah folder ada\n",
        "  if not os.path.exists(TRAIN_PATH) or not os.path.exists(VAL_PATH):\n",
        "      raise FileNotFoundError(\"‚ùå Folder train atau validation tidak ditemukan! Pastikan dataset sudah diproses.\")\n",
        "\n",
        "  # üîπ Menyimpan path gambar dan label\n",
        "  train_images_path, val_images_path = [], []\n",
        "  train_labels, val_labels = [], []\n",
        "\n",
        "  # üîπ Fungsi untuk mengumpulkan gambar dari folder\n",
        "  def collect_images(folder_path, label_storage, image_storage):\n",
        "      for label in CLASSES:\n",
        "          label_path = os.path.join(folder_path, label)\n",
        "\n",
        "          if not os.path.exists(label_path):\n",
        "              print(f\"‚ö†Ô∏è Folder tidak ditemukan: {label_path}\")\n",
        "              continue\n",
        "\n",
        "          image_files = [\n",
        "              os.path.join(label_path, f)\n",
        "              for f in os.listdir(label_path)\n",
        "              if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "          ]\n",
        "\n",
        "          if len(image_files) == 0:\n",
        "              print(f\"‚ö†Ô∏è Tidak ada gambar di kelas '{label}', dilewati.\")\n",
        "              continue\n",
        "\n",
        "          image_storage.extend(image_files)\n",
        "          label_storage.extend([label] * len(image_files))\n",
        "\n",
        "  # üîπ Mengumpulkan data train dan validation\n",
        "  collect_images(TRAIN_PATH, train_labels, train_images_path)\n",
        "  collect_images(VAL_PATH, val_labels, val_images_path)\n",
        "\n",
        "  # üîπ Konversi ke DataFrame (Opsional, untuk debugging)\n",
        "  train_df = pd.DataFrame({\"image_path\": train_images_path, \"label\": train_labels})\n",
        "  val_df = pd.DataFrame({\"image_path\": val_images_path, \"label\": val_labels})\n",
        "\n",
        "  # üîπ One-Hot Encoding untuk label\n",
        "  one_hot_enc = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "  train_labels_onehot = one_hot_enc.fit_transform(pd.DataFrame(train_labels))\n",
        "  val_labels_onehot = one_hot_enc.transform(pd.DataFrame(val_labels))\n",
        "\n",
        "  # üîπ Mengacak data train untuk menghindari bias\n",
        "  train_images_path, train_labels, train_labels_onehot = shuffle(\n",
        "      train_images_path, train_labels, train_labels_onehot, random_state=42\n",
        "  )\n",
        "\n",
        "  # üîπ Print hasil pemrosesan\n",
        "  print(\"\\n‚úÖ Dataset berhasil diproses!\")\n",
        "  print(f\"üîπ Jumlah gambar Train     : {len(train_images_path)}\")\n",
        "  print(f\"üîπ Jumlah gambar Validation: {len(val_images_path)}\")"
      ],
      "metadata": {
        "id": "2LP3-3YDFojZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94d528c1-2afc-4a9b-add9-fd511b42a7da"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Dataset berhasil diproses!\n",
            "üîπ Jumlah gambar Train     : 2684\n",
            "üîπ Jumlah gambar Validation: 671\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xlsxwriter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnJt4Lz13FCF",
        "outputId": "3ed5f7e9-7706-4b73-bb1c-5fb9699ca6c0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.11/dist-packages (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from environment_setup import CLASSES  # Ambil daftar kelas\n",
        "\n",
        "# üîπ Pastikan variabel train_images_path, train_labels, train_labels_onehot sudah ada dari pemrosesan sebelumnya!\n",
        "\n",
        "# üîπ Menentukan parameter\n",
        "N_SPLITS = 5\n",
        "OUTPUT_FILE = \"dataset_splits.xlsx\"\n",
        "\n",
        "# üîπ Pastikan train_labels_onehot dalam format NumPy array\n",
        "train_labels_onehot = np.array(train_labels_onehot)\n",
        "\n",
        "# üîπ K-Fold Split\n",
        "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
        "\n",
        "with pd.ExcelWriter(OUTPUT_FILE, engine=\"xlsxwriter\") as writer_excel:\n",
        "    for i, (train_idx, val_idx) in enumerate(kf.split(train_images_path), start=1):\n",
        "        fold_train_images = [train_images_path[idx] for idx in train_idx]\n",
        "        fold_val_images = [train_images_path[idx] for idx in val_idx]\n",
        "\n",
        "        fold_train_labels = [train_labels[idx] for idx in train_idx]\n",
        "        fold_val_labels = [train_labels[idx] for idx in val_idx]\n",
        "\n",
        "        fold_train_labels_onehot = train_labels_onehot[train_idx, :]\n",
        "        fold_val_labels_onehot = train_labels_onehot[val_idx, :]\n",
        "\n",
        "        # üîπ Fungsi untuk membuat DataFrame\n",
        "        def create_dataframe(image_paths, labels, one_hot_labels):\n",
        "            df = pd.DataFrame({\"image_path\": image_paths, \"label\": labels})\n",
        "            for j, class_name in enumerate(CLASSES):\n",
        "                df[class_name] = one_hot_labels[:, j]  # ‚úÖ Perbaikan indexing\n",
        "            return df\n",
        "\n",
        "        train_df = create_dataframe(fold_train_images, fold_train_labels, fold_train_labels_onehot)\n",
        "        val_df = create_dataframe(fold_val_images, fold_val_labels, fold_val_labels_onehot)\n",
        "\n",
        "        # üîπ Menyimpan ke Excel\n",
        "        train_df.to_excel(writer_excel, sheet_name=f\"Fold_{i}_Train\", index=False)\n",
        "        val_df.to_excel(writer_excel, sheet_name=f\"Fold_{i}_Val\", index=False)\n",
        "\n",
        "print(f\"‚úÖ Data split telah disimpan di {OUTPUT_FILE}\")\n"
      ],
      "metadata": {
        "id": "68LikH78FwX-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b6608c9-220d-416b-f062-c9d607993dee"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Data split telah disimpan di dataset_splits.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "# üîπ Konstanta\n",
        "EXCEL_FILENAME = \"dataset_splits.xlsx\"  # Nama file Excel yang digunakan\n",
        "IMG_SIZE = 224  # Ukuran gambar yang diinginkan\n",
        "LABEL_COLUMNS = ['Healthy', 'Hispa', 'BrownSpot', 'LeafBlast']  # Nama label yang benar\n",
        "\n",
        "def getArrFromExcel(sheet_name):\n",
        "    \"\"\"\n",
        "    Membaca dataset dari file Excel dan mengonversinya menjadi array gambar dan label.\n",
        "\n",
        "    Parameters:\n",
        "        sheet_name (str): Nama sheet dalam file Excel yang akan dibaca.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (numpy.ndarray dari gambar, numpy.ndarray dari label)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # üîπ Membaca file Excel dengan engine openpyxl (jika belum terinstal, gunakan xlsxwriter)\n",
        "        df = pd.read_excel(EXCEL_FILENAME, sheet_name=sheet_name, engine=\"openpyxl\")\n",
        "        print(f\"‚úÖ Sheet '{sheet_name}' berhasil dibaca.\")\n",
        "\n",
        "        # üîπ Periksa apakah 'image_path' ada dalam dataset\n",
        "        if \"image_path\" not in df.columns:\n",
        "            print(\"‚ùå Kolom 'image_path' tidak ditemukan dalam file Excel! Periksa kembali format dataset.\")\n",
        "            return None, None\n",
        "\n",
        "        # üîπ Menampilkan kolom yang tersedia\n",
        "        print(f\"üìä Kolom yang ditemukan di dataset: {list(df.columns)}\")\n",
        "\n",
        "        # üîπ Periksa apakah semua kolom label one-hot ada\n",
        "        missing_labels = [col for col in LABEL_COLUMNS if col not in df.columns]\n",
        "        if missing_labels:\n",
        "            print(f\"‚ö†Ô∏è Kolom label one-hot tidak ditemukan: {missing_labels}. Periksa kembali file Excel!\")\n",
        "            return None, None\n",
        "\n",
        "        # üîπ Mengambil path gambar dan label one-hot\n",
        "        images_path = df[\"image_path\"].values\n",
        "        labels = df[LABEL_COLUMNS].values  # Menggunakan label yang benar\n",
        "\n",
        "        # üîπ Menyimpan array gambar\n",
        "        images_arr = []\n",
        "\n",
        "        for image_path in tqdm(images_path, desc=\"üì∏ Loading Images\"):\n",
        "            try:\n",
        "                img = load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "                images_arr.append(img_to_array(img))\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Error loading image {image_path}: {e}\")\n",
        "                continue  # Lewati gambar yang gagal dimuat\n",
        "\n",
        "        # üîπ Konversi ke NumPy array\n",
        "        images_arr = np.array(images_arr, dtype=\"float32\")\n",
        "        labels = np.array(labels, dtype=\"float32\")\n",
        "\n",
        "        print(f\"‚úÖ Dataset dari '{sheet_name}' berhasil dikonversi!\")\n",
        "        return images_arr, labels\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error membaca file Excel: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# üîπ Contoh penggunaan\n",
        "images, labels = getArrFromExcel(\"Fold_1_Train\")\n",
        "\n",
        "if images is not None and labels is not None:\n",
        "    print(f\"‚úÖ Dataset berhasil dimuat: Gambar {images.shape}, Label {labels.shape}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Terjadi kesalahan saat memuat dataset.\")\n"
      ],
      "metadata": {
        "id": "RdVLaNQoodDJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c381bd9-6e65-4a6e-a236-06bff581a720"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sheet 'Fold_1_Train' berhasil dibaca.\n",
            "üìä Kolom yang ditemukan di dataset: ['image_path', 'label', 'Healthy', 'Hispa', 'BrownSpot', 'LeafBlast']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üì∏ Loading Images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2147/2147 [04:07<00:00,  8.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dataset dari 'Fold_1_Train' berhasil dikonversi!\n",
            "‚úÖ Dataset berhasil dimuat: Gambar (2147, 224, 224, 3), Label (2147, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, applications\n",
        "\n",
        "# üîπ Konstanta\n",
        "IMG_SIZE = 224\n",
        "NUM_CLASSES = 4\n",
        "\n",
        "def build_scratch_model():\n",
        "    \"\"\"Model tanpa transfer learning (train from scratch)\"\"\"\n",
        "    base_model = applications.MobileNetV2(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3), weights=None)\n",
        "    base_model.trainable = True\n",
        "    return tf.keras.Sequential([\n",
        "        base_model,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(512, activation=\"relu\"),\n",
        "        layers.Dense(NUM_CLASSES, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "def build_fixed_feature_extraction_model():\n",
        "    \"\"\"Transfer Learning - Fixed Feature Extraction\"\"\"\n",
        "    base_model = applications.MobileNetV2(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3), weights=\"imagenet\")\n",
        "    base_model.trainable = False  # Freeze seluruh model\n",
        "    return tf.keras.Sequential([\n",
        "        base_model,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(512, activation=\"relu\"),\n",
        "        layers.Dense(NUM_CLASSES, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "def build_finetune_first_layer():\n",
        "    \"\"\"Transfer Learning - Fine-Tuning First Trainable Layer\"\"\"\n",
        "    base_model = applications.MobileNetV2(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3), weights=\"imagenet\")\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # üîπ Unfreeze layer pertama yang bisa dilatih (skip layer input)\n",
        "    first_trainable_layer = next((layer for layer in base_model.layers if \"conv\" in layer.name), None)\n",
        "    if first_trainable_layer:\n",
        "        first_trainable_layer.trainable = True\n",
        "\n",
        "    return tf.keras.Sequential([\n",
        "        base_model,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(512, activation=\"relu\"),\n",
        "        layers.Dense(NUM_CLASSES, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "def build_finetune_middle_layer():\n",
        "    \"\"\"Transfer Learning - Fine-Tuning Middle Layer\"\"\"\n",
        "    base_model = applications.MobileNetV2(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3), weights=\"imagenet\")\n",
        "    base_model.trainable = False\n",
        "    total_layers = len(base_model.layers)\n",
        "\n",
        "    middle_layer_index = total_layers // 2  # Indeks tengah\n",
        "    fine_tune_range = 5  # Bisa diubah sesuai kebutuhan\n",
        "\n",
        "    # üîπ Pastikan indeks tidak keluar batas\n",
        "    start_idx = max(0, middle_layer_index - fine_tune_range)\n",
        "    end_idx = min(total_layers, middle_layer_index + fine_tune_range)\n",
        "\n",
        "    for layer in base_model.layers[start_idx:end_idx]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    return tf.keras.Sequential([\n",
        "        base_model,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(512, activation=\"relu\"),\n",
        "        layers.Dense(NUM_CLASSES, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "def build_finetune_last_layer(ft_layers=25):\n",
        "    \"\"\"Transfer Learning - Fine-Tuning Last Layer\"\"\"\n",
        "    base_model = applications.MobileNetV2(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3), weights=\"imagenet\")\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # üîπ Pastikan tidak melebihi jumlah layer\n",
        "    ft_layers = min(ft_layers, len(base_model.layers))\n",
        "\n",
        "    for layer in base_model.layers[-ft_layers:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    return tf.keras.Sequential([\n",
        "        base_model,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(512, activation=\"relu\"),\n",
        "        layers.Dense(NUM_CLASSES, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "# üîπ Inisialisasi model\n",
        "models = {\n",
        "    \"Scratch\": build_scratch_model(),\n",
        "    \"Fixed_Feature\": build_fixed_feature_extraction_model(),\n",
        "    \"Fine_Tune_First\": build_finetune_first_layer(),\n",
        "    \"Fine_Tune_Middle\": build_finetune_middle_layer(),\n",
        "    \"Fine_Tune_Last\": build_finetune_last_layer()\n",
        "}\n",
        "\n",
        "# üîπ Kompilasi model\n",
        "for name, model in models.items():\n",
        "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    print(f\"‚úÖ Model '{name}' siap untuk dilatih!\")\n"
      ],
      "metadata": {
        "id": "iLqXUZZXogMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff756a28-3954-4cea-cd86-d270647a8bac"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model 'Scratch' siap untuk dilatih!\n",
            "‚úÖ Model 'Fixed_Feature' siap untuk dilatih!\n",
            "‚úÖ Model 'Fine_Tune_First' siap untuk dilatih!\n",
            "‚úÖ Model 'Fine_Tune_Middle' siap untuk dilatih!\n",
            "‚úÖ Model 'Fine_Tune_Last' siap untuk dilatih!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "\n",
        "# üîπ Konstanta\n",
        "EXCEL_FILENAME = \"dataset_splits.xlsx\"\n",
        "IMG_SIZE = 224\n",
        "LABEL_COLUMNS = ['Healthy', 'Hispa', 'BrownSpot', 'LeafBlast']\n",
        "BATCH_SIZE = 16  # Kurangi batch untuk hemat RAM\n",
        "EPOCHS = 20\n",
        "MODEL_SAVE_DIR = \"saved_models\"\n",
        "N_SPLITS = 5\n",
        "\n",
        "# üîπ Fungsi untuk membaca dataset dari Excel (gunakan generator agar tidak membebani RAM)\n",
        "def load_image_data(sheet_name):\n",
        "    try:\n",
        "        df = pd.read_excel(EXCEL_FILENAME, sheet_name=sheet_name)\n",
        "        print(f\"‚úÖ Sheet '{sheet_name}' berhasil dibaca.\")\n",
        "\n",
        "        if not all(col in df.columns for col in LABEL_COLUMNS):\n",
        "            print(f\"‚ö†Ô∏è Kolom label one-hot tidak ditemukan dalam file Excel.\")\n",
        "            return None, None\n",
        "\n",
        "        images_path = df[\"image_path\"].values\n",
        "        labels = df[LABEL_COLUMNS].values\n",
        "\n",
        "        def image_generator():\n",
        "            for image_path in images_path:\n",
        "                try:\n",
        "                    img = load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "                    yield img_to_array(img) / 255.0  # Normalisasi di sini\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Error loading image {image_path}: {e}\")\n",
        "                    yield np.zeros((IMG_SIZE, IMG_SIZE, 3))  # Gambar dummy jika gagal\n",
        "\n",
        "        return np.array(list(image_generator()), dtype=\"float32\"), np.array(labels, dtype=\"float32\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error membaca file Excel: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# üîπ Model yang akan digunakan\n",
        "models = {\n",
        "    \"Scratch\": build_scratch_model(),\n",
        "    \"Fixed_Feature\": build_fixed_feature_extraction_model(),\n",
        "    \"Fine_Tune_First\": build_finetune_first_layer(),\n",
        "    \"Fine_Tune_Middle\": build_finetune_middle_layer(),\n",
        "    \"Fine_Tune_Last\": build_finetune_last_layer()\n",
        "}\n",
        "\n",
        "# üîπ Simpan hasil cross-validation\n",
        "cv_results = {name: [] for name in models.keys()}\n",
        "\n",
        "# üîπ Looping 5-Fold Cross Validation\n",
        "for fold in range(1, N_SPLITS + 1):\n",
        "    print(f\"\\nüîÑ Processing Fold {fold}/{N_SPLITS}\")\n",
        "\n",
        "    # Load dataset dengan generator\n",
        "    train_images, train_labels = load_image_data(f\"Fold_{fold}_Train\")\n",
        "    val_images, val_labels = load_image_data(f\"Fold_{fold}_Val\")\n",
        "\n",
        "    if train_images is None or val_images is None:\n",
        "        print(f\"‚ùå Data Fold {fold} tidak bisa dimuat. Lewati fold ini.\")\n",
        "        continue\n",
        "\n",
        "    # Gunakan ImageDataGenerator agar tidak menyimpan semua data di RAM\n",
        "    train_datagen = ImageDataGenerator()\n",
        "    val_datagen = ImageDataGenerator()\n",
        "\n",
        "    train_generator = train_datagen.flow(train_images, train_labels, batch_size=BATCH_SIZE)\n",
        "    val_generator = val_datagen.flow(val_images, val_labels, batch_size=BATCH_SIZE)\n",
        "\n",
        "    # Hapus dataset dari RAM setelah membuat generator\n",
        "    del train_images, train_labels, val_images, val_labels\n",
        "    gc.collect()\n",
        "\n",
        "    # Train semua model di fold ini\n",
        "    for model_name, model in models.items():\n",
        "        print(f\"\\nüöÄ Training Model: {model_name} (Fold {fold})\")\n",
        "\n",
        "        # üîπ Kompilasi ulang model setiap fold agar tidak ada memory leak\n",
        "        model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "            loss=\"categorical_crossentropy\",\n",
        "            metrics=[\"accuracy\"]\n",
        "        )\n",
        "\n",
        "        # Callbacks\n",
        "        save_path = f\"{MODEL_SAVE_DIR}/{model_name}_Fold{fold}.h5\"\n",
        "        callbacks = [\n",
        "            EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
        "            ModelCheckpoint(save_path, save_best_only=True, monitor=\"val_loss\"),\n",
        "            ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3)\n",
        "        ]\n",
        "\n",
        "        # Training dengan `fit_generator()` agar hemat RAM\n",
        "        history = model.fit(\n",
        "            train_generator,\n",
        "            validation_data=val_generator,\n",
        "            epochs=EPOCHS,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        # Simpan hasil fold ini\n",
        "        best_val_loss = min(history.history[\"val_loss\"])\n",
        "        best_val_acc = max(history.history[\"val_accuracy\"])\n",
        "        cv_results[model_name].append({\"Fold\": fold, \"Val_Loss\": best_val_loss, \"Val_Acc\": best_val_acc})\n",
        "\n",
        "        print(f\"‚úÖ {model_name} (Fold {fold}) selesai! Best Val Loss: {best_val_loss:.4f}, Best Val Acc: {best_val_acc:.4f}\")\n",
        "\n",
        "        # Hapus model dari RAM setelah selesai\n",
        "        del model\n",
        "        gc.collect()\n",
        "\n",
        "# üîπ Rata-rata hasil cross-validation\n",
        "final_results = []\n",
        "for model_name, results in cv_results.items():\n",
        "    avg_val_loss = np.mean([r[\"Val_Loss\"] for r in results])\n",
        "    avg_val_acc = np.mean([r[\"Val_Acc\"] for r in results])\n",
        "    final_results.append({\"Model\": model_name, \"Avg_Val_Loss\": avg_val_loss, \"Avg_Val_Acc\": avg_val_acc})\n",
        "\n",
        "# üîπ Simpan hasil akhir\n",
        "df_final = pd.DataFrame(final_results).sort_values(by=\"Avg_Val_Acc\", ascending=False)\n",
        "print(\"\\nüìä Hasil Cross-Validation:\")\n",
        "print(df_final)\n",
        "df_final.to_csv(\"cv_model_comparison.csv\", index=False)\n",
        "\n",
        "# üîπ Model terbaik berdasarkan rata-rata\n",
        "best_model_name = df_final.iloc[0][\"Model\"]\n",
        "print(f\"\\nüèÜ Model terbaik setelah 5-Fold CV: {best_model_name} dengan rata-rata akurasi {df_final.iloc[0]['Avg_Val_Acc']:.4f}\")\n"
      ],
      "metadata": {
        "id": "L0KPRzu_r-4_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be63e7af-1024-4608-952b-0d449e15166b"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîÑ Processing Fold 1/5\n",
            "‚úÖ Sheet 'Fold_1_Train' berhasil dibaca.\n",
            "‚úÖ Sheet 'Fold_1_Val' berhasil dibaca.\n",
            "\n",
            "üöÄ Training Model: Scratch (Fold 1)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3975 - loss: 2.4985"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m540s\u001b[0m 4s/step - accuracy: 0.3978 - loss: 2.4960 - val_accuracy: 0.1620 - val_loss: 1.8436 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4796 - loss: 1.5798"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m466s\u001b[0m 3s/step - accuracy: 0.4797 - loss: 1.5790 - val_accuracy: 0.4153 - val_loss: 1.6462 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5533 - loss: 1.3895"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m477s\u001b[0m 4s/step - accuracy: 0.5533 - loss: 1.3891 - val_accuracy: 0.1881 - val_loss: 1.4063 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 3s/step - accuracy: 0.5093 - loss: 1.3710 - val_accuracy: 0.4153 - val_loss: 1.5793 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m451s\u001b[0m 3s/step - accuracy: 0.5505 - loss: 1.1182 - val_accuracy: 0.4153 - val_loss: 1.5731 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5635 - loss: 1.0343"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 3s/step - accuracy: 0.5635 - loss: 1.0342 - val_accuracy: 0.4153 - val_loss: 1.3785 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m482s\u001b[0m 3s/step - accuracy: 0.5662 - loss: 0.9966 - val_accuracy: 0.4153 - val_loss: 1.5077 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m503s\u001b[0m 3s/step - accuracy: 0.5863 - loss: 1.0161 - val_accuracy: 0.4153 - val_loss: 1.4508 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m525s\u001b[0m 4s/step - accuracy: 0.6139 - loss: 0.9485 - val_accuracy: 0.4153 - val_loss: 1.4661 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 3s/step - accuracy: 0.6280 - loss: 0.9382 - val_accuracy: 0.4153 - val_loss: 1.5564 - learning_rate: 5.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 3s/step - accuracy: 0.6772 - loss: 0.8032 - val_accuracy: 0.4153 - val_loss: 1.7437 - learning_rate: 5.0000e-04\n",
            "‚úÖ Scratch (Fold 1) selesai! Best Val Loss: 1.3785, Best Val Acc: 0.4153\n",
            "\n",
            "üöÄ Training Model: Fixed_Feature (Fold 1)\n",
            "Epoch 1/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630ms/step - accuracy: 0.4808 - loss: 1.4944"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 807ms/step - accuracy: 0.4812 - loss: 1.4932 - val_accuracy: 0.5866 - val_loss: 1.0269 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 775ms/step - accuracy: 0.7457 - loss: 0.6535 - val_accuracy: 0.6238 - val_loss: 1.0805 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 781ms/step - accuracy: 0.8199 - loss: 0.4396 - val_accuracy: 0.6145 - val_loss: 1.0698 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 773ms/step - accuracy: 0.8458 - loss: 0.3711 - val_accuracy: 0.5996 - val_loss: 1.1763 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 927ms/step - accuracy: 0.8969 - loss: 0.2796 - val_accuracy: 0.6685 - val_loss: 1.0477 - learning_rate: 5.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 826ms/step - accuracy: 0.9340 - loss: 0.1964 - val_accuracy: 0.6462 - val_loss: 1.1037 - learning_rate: 5.0000e-04\n",
            "‚úÖ Fixed_Feature (Fold 1) selesai! Best Val Loss: 1.0269, Best Val Acc: 0.6685\n",
            "\n",
            "üöÄ Training Model: Fine_Tune_First (Fold 1)\n",
            "Epoch 1/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4907 - loss: 1.5124"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 2s/step - accuracy: 0.4910 - loss: 1.5117 - val_accuracy: 0.5866 - val_loss: 1.0328 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.7277 - loss: 0.6951 - val_accuracy: 0.5885 - val_loss: 1.0660 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.8027 - loss: 0.4834 - val_accuracy: 0.6034 - val_loss: 1.0560 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 1s/step - accuracy: 0.8431 - loss: 0.3875 - val_accuracy: 0.6071 - val_loss: 1.3552 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 1s/step - accuracy: 0.8768 - loss: 0.3412 - val_accuracy: 0.6480 - val_loss: 1.1255 - learning_rate: 5.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.9428 - loss: 0.1836 - val_accuracy: 0.6387 - val_loss: 1.1717 - learning_rate: 5.0000e-04\n",
            "‚úÖ Fine_Tune_First (Fold 1) selesai! Best Val Loss: 1.0328, Best Val Acc: 0.6480\n",
            "\n",
            "üöÄ Training Model: Fine_Tune_Middle (Fold 1)\n",
            "Epoch 1/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905ms/step - accuracy: 0.4727 - loss: 1.5397"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 1s/step - accuracy: 0.4730 - loss: 1.5387 - val_accuracy: 0.4693 - val_loss: 1.2119 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901ms/step - accuracy: 0.6574 - loss: 0.9315"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.6574 - loss: 0.9313 - val_accuracy: 0.6182 - val_loss: 1.0531 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903ms/step - accuracy: 0.7281 - loss: 0.6957"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.7281 - loss: 0.6958 - val_accuracy: 0.6331 - val_loss: 0.9004 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 1s/step - accuracy: 0.7884 - loss: 0.5178 - val_accuracy: 0.6592 - val_loss: 0.9201 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 1s/step - accuracy: 0.8379 - loss: 0.4097 - val_accuracy: 0.6685 - val_loss: 0.9538 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 1s/step - accuracy: 0.8725 - loss: 0.3258 - val_accuracy: 0.6890 - val_loss: 1.0357 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.9036 - loss: 0.2594 - val_accuracy: 0.7020 - val_loss: 0.9583 - learning_rate: 5.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 1s/step - accuracy: 0.9463 - loss: 0.1615 - val_accuracy: 0.7225 - val_loss: 1.0446 - learning_rate: 5.0000e-04\n",
            "‚úÖ Fine_Tune_Middle (Fold 1) selesai! Best Val Loss: 0.9004, Best Val Acc: 0.7225\n",
            "\n",
            "üöÄ Training Model: Fine_Tune_Last (Fold 1)\n",
            "Epoch 1/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815ms/step - accuracy: 0.4636 - loss: 1.8754"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 980ms/step - accuracy: 0.4639 - loss: 1.8733 - val_accuracy: 0.4451 - val_loss: 7.8334 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 965ms/step - accuracy: 0.5795 - loss: 1.2449 - val_accuracy: 0.4171 - val_loss: 16.0833 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.6200 - loss: 1.1561 - val_accuracy: 0.4749 - val_loss: 8.9045 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 967ms/step - accuracy: 0.6923 - loss: 0.8000 - val_accuracy: 0.4358 - val_loss: 9.6205 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803ms/step - accuracy: 0.7546 - loss: 0.5956"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 966ms/step - accuracy: 0.7548 - loss: 0.5955 - val_accuracy: 0.4767 - val_loss: 5.3433 - learning_rate: 5.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806ms/step - accuracy: 0.8169 - loss: 0.4790"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 965ms/step - accuracy: 0.8169 - loss: 0.4791 - val_accuracy: 0.4674 - val_loss: 4.4083 - learning_rate: 5.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822ms/step - accuracy: 0.8158 - loss: 0.4686"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 978ms/step - accuracy: 0.8159 - loss: 0.4685 - val_accuracy: 0.5084 - val_loss: 2.8585 - learning_rate: 5.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 969ms/step - accuracy: 0.8459 - loss: 0.3964 - val_accuracy: 0.4972 - val_loss: 3.7812 - learning_rate: 5.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 981ms/step - accuracy: 0.8512 - loss: 0.3724 - val_accuracy: 0.5251 - val_loss: 2.9324 - learning_rate: 5.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812ms/step - accuracy: 0.8734 - loss: 0.3155"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 974ms/step - accuracy: 0.8733 - loss: 0.3156 - val_accuracy: 0.5661 - val_loss: 2.2815 - learning_rate: 5.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 976ms/step - accuracy: 0.9009 - loss: 0.2770 - val_accuracy: 0.5400 - val_loss: 2.7381 - learning_rate: 5.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 1s/step - accuracy: 0.8828 - loss: 0.3266 - val_accuracy: 0.4879 - val_loss: 2.6522 - learning_rate: 5.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829ms/step - accuracy: 0.9059 - loss: 0.2454"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 986ms/step - accuracy: 0.9058 - loss: 0.2457 - val_accuracy: 0.5568 - val_loss: 1.8466 - learning_rate: 5.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807ms/step - accuracy: 0.9259 - loss: 0.2340"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - accuracy: 0.9258 - loss: 0.2340 - val_accuracy: 0.6965 - val_loss: 1.4490 - learning_rate: 5.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 987ms/step - accuracy: 0.9198 - loss: 0.2041 - val_accuracy: 0.6760 - val_loss: 1.8460 - learning_rate: 5.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 1s/step - accuracy: 0.9314 - loss: 0.1807 - val_accuracy: 0.6648 - val_loss: 1.6768 - learning_rate: 5.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 972ms/step - accuracy: 0.9549 - loss: 0.1357 - val_accuracy: 0.5978 - val_loss: 2.4537 - learning_rate: 5.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 967ms/step - accuracy: 0.9358 - loss: 0.1848 - val_accuracy: 0.6331 - val_loss: 2.1348 - learning_rate: 2.5000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 1s/step - accuracy: 0.9760 - loss: 0.0678 - val_accuracy: 0.6685 - val_loss: 2.1353 - learning_rate: 2.5000e-04\n",
            "‚úÖ Fine_Tune_Last (Fold 1) selesai! Best Val Loss: 1.4490, Best Val Acc: 0.6965\n",
            "\n",
            "üîÑ Processing Fold 2/5\n",
            "‚úÖ Sheet 'Fold_2_Train' berhasil dibaca.\n",
            "‚úÖ Sheet 'Fold_2_Val' berhasil dibaca.\n",
            "\n",
            "üöÄ Training Model: Scratch (Fold 2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5176 - loss: 1.2073"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m495s\u001b[0m 3s/step - accuracy: 0.5175 - loss: 1.2073 - val_accuracy: 0.4618 - val_loss: 1.5889 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5499 - loss: 1.1556"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m520s\u001b[0m 4s/step - accuracy: 0.5499 - loss: 1.1553 - val_accuracy: 0.2235 - val_loss: 1.4406 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5270 - loss: 1.0926"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m474s\u001b[0m 3s/step - accuracy: 0.5272 - loss: 1.0925 - val_accuracy: 0.4618 - val_loss: 1.4028 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m501s\u001b[0m 3s/step - accuracy: 0.5861 - loss: 1.0179 - val_accuracy: 0.4618 - val_loss: 1.6062 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 3s/step - accuracy: 0.5667 - loss: 1.0561 - val_accuracy: 0.4618 - val_loss: 1.4758 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5932 - loss: 1.0076"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 3s/step - accuracy: 0.5931 - loss: 1.0077 - val_accuracy: 0.4618 - val_loss: 1.3992 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 3s/step - accuracy: 0.5896 - loss: 1.0037 - val_accuracy: 0.4618 - val_loss: 1.6014 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m452s\u001b[0m 3s/step - accuracy: 0.5836 - loss: 0.9989 - val_accuracy: 0.4618 - val_loss: 1.6071 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 3s/step - accuracy: 0.5998 - loss: 0.9778 - val_accuracy: 0.4618 - val_loss: 1.5207 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 3s/step - accuracy: 0.5826 - loss: 0.9929 - val_accuracy: 0.4618 - val_loss: 1.6945 - learning_rate: 5.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m466s\u001b[0m 3s/step - accuracy: 0.6235 - loss: 0.9272 - val_accuracy: 0.4618 - val_loss: 1.6054 - learning_rate: 5.0000e-04\n",
            "‚úÖ Scratch (Fold 2) selesai! Best Val Loss: 1.3992, Best Val Acc: 0.4618\n",
            "\n",
            "üöÄ Training Model: Fixed_Feature (Fold 2)\n",
            "Epoch 1/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662ms/step - accuracy: 0.6688 - loss: 0.9376"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 856ms/step - accuracy: 0.6687 - loss: 0.9377 - val_accuracy: 0.7039 - val_loss: 0.7574 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664ms/step - accuracy: 0.7939 - loss: 0.5075"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 834ms/step - accuracy: 0.7938 - loss: 0.5077 - val_accuracy: 0.6909 - val_loss: 0.7223 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 978ms/step - accuracy: 0.8190 - loss: 0.4358 - val_accuracy: 0.7151 - val_loss: 0.7943 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 821ms/step - accuracy: 0.8702 - loss: 0.3352 - val_accuracy: 0.7356 - val_loss: 0.7768 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 1s/step - accuracy: 0.8951 - loss: 0.2628 - val_accuracy: 0.7300 - val_loss: 0.8251 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 956ms/step - accuracy: 0.9437 - loss: 0.1601 - val_accuracy: 0.7225 - val_loss: 0.8208 - learning_rate: 5.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 967ms/step - accuracy: 0.9630 - loss: 0.1252 - val_accuracy: 0.7356 - val_loss: 0.7853 - learning_rate: 5.0000e-04\n",
            "‚úÖ Fixed_Feature (Fold 2) selesai! Best Val Loss: 0.7223, Best Val Acc: 0.7356\n",
            "\n",
            "üöÄ Training Model: Fine_Tune_First (Fold 2)\n",
            "Epoch 1/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6230 - loss: 1.0880"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 2s/step - accuracy: 0.6231 - loss: 1.0875 - val_accuracy: 0.6834 - val_loss: 0.7188 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.7874 - loss: 0.5469 - val_accuracy: 0.6872 - val_loss: 0.7986 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 2s/step - accuracy: 0.8188 - loss: 0.4592 - val_accuracy: 0.7281 - val_loss: 0.7327 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 2s/step - accuracy: 0.8646 - loss: 0.3433 - val_accuracy: 0.7207 - val_loss: 0.7961 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 2s/step - accuracy: 0.9210 - loss: 0.2306 - val_accuracy: 0.7244 - val_loss: 0.7985 - learning_rate: 5.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 2s/step - accuracy: 0.9547 - loss: 0.1664 - val_accuracy: 0.7281 - val_loss: 0.8138 - learning_rate: 5.0000e-04\n",
            "‚úÖ Fine_Tune_First (Fold 2) selesai! Best Val Loss: 0.7188, Best Val Acc: 0.7281\n",
            "\n",
            "üöÄ Training Model: Fine_Tune_Middle (Fold 2)\n",
            "Epoch 1/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969ms/step - accuracy: 0.7003 - loss: 0.7771"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 1s/step - accuracy: 0.7002 - loss: 0.7773 - val_accuracy: 0.7002 - val_loss: 0.8056 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972ms/step - accuracy: 0.7597 - loss: 0.6271"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 1s/step - accuracy: 0.7597 - loss: 0.6272 - val_accuracy: 0.7076 - val_loss: 0.7401 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956ms/step - accuracy: 0.7945 - loss: 0.4977"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 1s/step - accuracy: 0.7945 - loss: 0.4978 - val_accuracy: 0.7393 - val_loss: 0.7118 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 1s/step - accuracy: 0.8343 - loss: 0.4014 - val_accuracy: 0.7561 - val_loss: 0.7673 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - accuracy: 0.8766 - loss: 0.3272 - val_accuracy: 0.7244 - val_loss: 1.1018 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - accuracy: 0.8725 - loss: 0.3170 - val_accuracy: 0.7393 - val_loss: 0.9899 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m112/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m21s\u001b[0m 951ms/step - accuracy: 0.9005 - loss: 0.2498"
          ]
        }
      ]
    }
  ]
}